{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8032d2",
   "metadata": {},
   "source": [
    "$k$-NN\n",
    "===\n",
    "\n",
    "**Autor:** Mateus de Jesus Mendes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e9043",
   "metadata": {},
   "source": [
    "# Introdu√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c0b6e",
   "metadata": {},
   "source": [
    "Este *Jupyter Notebook* tem por objetivo implementar o algoritmo $k$-NN para induzir um modelo a partir dos elementos do *dataset* `xtb_dataset.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172e005",
   "metadata": {},
   "source": [
    "## Fundamenta√ß√£o Te√≥rica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870cce24",
   "metadata": {},
   "source": [
    "### Contextualiza√ß√£o geral\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c2f02a",
   "metadata": {},
   "source": [
    "O algoritmo *$k$-Nearest Neighbors* ($k$-NN) √© um estimador n√£o param√©trico, baseado em inst√¢ncias e pertencente √† classe dos m√©todos de aprendizado supervisionado por similaridade **\\[[1, 2]()\\]**. Diferentemente de modelos param√©tricos tradicionais, o $k$-NN n√£o realiza uma etapa expl√≠cita de treinamento no sentido cl√°ssico: n√£o h√° ajuste de coeficientes, nem infer√™ncia de uma fun√ß√£o global que relacione entradas e sa√≠das. Em vez disso, o modelo armazena o conjunto de dados de treinamento e realiza predi√ß√µes exclusivamente com base na proximidade geom√©trica entre amostras no espa√ßo de atributos **\\[[3]()\\]**.\n",
    "\n",
    "Essa caracter√≠stica faz do $k$-NN um m√©todo conceitualmente simples, por√©m poderoso, especialmente adequado para problemas nos quais a rela√ß√£o entre vari√°veis √© altamente local, potencialmente n√£o linear e dif√≠cil de ser capturada por fun√ß√µes globais suaves **\\[[1, 4]()\\]**. Por outro lado, essa mesma propriedade imp√µe limita√ß√µes claras em termos de escalabilidade, interpretabilidade e extrapola√ß√£o fora do dom√≠nio amostrado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19dfa5",
   "metadata": {},
   "source": [
    "### Representa√ß√£o do espa√ßo de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f960b4f",
   "metadata": {},
   "source": [
    "Considere um conjunto de dados de treinamento:\n",
    "$$\n",
    "\\mathcal{D} = {(\\mathbf{x}*i, y_i)}*{i=1}^{N}\n",
    "$$\n",
    "\n",
    "Em que:\n",
    "- $\\mathbf{x}_i \\in \\mathbb{R}^d$: Vetor de *features* da (i)-√©sima amostra\n",
    "- $y_i \\in \\mathbb{R}$: Valor alvo associado\n",
    "- $N$: N√∫mero total de observa√ß√µes \n",
    "\n",
    "O algoritmo kNN interpreta cada vetor $\\mathbf{x}_i$ como um ponto em um espa√ßo m√©trico de dimens√£o (d). A no√ß√£o de similaridade entre duas amostras √© formalizada por meio de uma fun√ß√£o de dist√¢ncia $d(\\mathbf{x}, \\mathbf{x}')$, cuja escolha √© um hiperpar√¢metro central do m√©todo **\\[[2, 3]()\\]**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182434bc",
   "metadata": {},
   "source": [
    "### M√©tricas de dist√¢ncia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcdab60",
   "metadata": {},
   "source": [
    "\n",
    "A dist√¢ncia entre duas observa√ß√µes $\\mathbf{x}$ e $\\mathbf{x}'$ pode ser definida de diversas formas. Entre as m√©tricas mais utilizadas destacam-se **\\[[1, 4]()\\]**:\n",
    "\n",
    "- **Dist√¢ncia Euclidiana**:\n",
    "$$\n",
    "d_2(\\mathbf{x}, \\mathbf{x}') = \\sqrt{\\sum_{j=1}^{d} (x_j - x'_j)^2}\n",
    "$$\n",
    "\n",
    "- **Dist√¢ncia Manhattan**:\n",
    "$$\n",
    "d_1(\\mathbf{x}, \\mathbf{x}') = \\sum_{j=1}^{d} |x_j - x'_j|\n",
    "$$\n",
    "\n",
    "A escolha da m√©trica influencia diretamente a geometria do espa√ßo de vizinhan√ßa. M√©tricas do tipo $\\ell_1$ (Manhattan) tendem a ser mais robustas em espa√ßos de alta dimensionalidade e em cen√°rios nos quais as *features* possuem naturezas f√≠sicas distintas ou distribui√ß√µes heterog√™neas **\\[[4, 5]()\\]**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c628876",
   "metadata": {},
   "source": [
    "### Defini√ß√£o dos $k$ vizinhos mais pr√≥ximos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc862295",
   "metadata": {},
   "source": [
    "Dada uma nova observa√ß√£o $\\mathbf{x}_*$, o algoritmo identifica o subconjunto:\n",
    "$$\n",
    "\\mathcal{N}_k(\\mathbf{x}_*) \\subset \\mathcal{D}\n",
    "$$\n",
    "\n",
    "O subconjunto encontrado √© composto pelos $k$ pontos do conjunto de treinamento que minimizam a dist√¢ncia $d(\\mathbf{x}_*, \\mathbf{x}_i)$ **\\[[1]()\\]**.\n",
    "\n",
    "O hiperpar√¢metro $k$ controla diretamente o vi√©s‚Äìvari√¢ncia do estimador:\n",
    "- Valores pequenos de $k$ produzem modelos altamente flex√≠veis, com baixo vi√©s (*bias*) e alta vari√¢ncia;\n",
    "- Valores maiores de $k$ suavizam as predi√ß√µes, aumentando o vi√©s e reduzindo a sensibilidade a ru√≠do local **\\[[2, 6]()\\]**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a2b73c",
   "metadata": {},
   "source": [
    "### Regra de predi√ß√£o para regress√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96ed5dc",
   "metadata": {},
   "source": [
    "No contexto de regress√£o, a predi√ß√£o associada a $\\mathbf{x}_*$ √© obtida como uma m√©dia dos valores alvo dos vizinhos selecionados. Na forma mais simples (*uniform weights*), tem-se:\n",
    "$$\n",
    "\\hat{y}(\\mathbf{x}_*) = \\frac{1}{k} \\sum_{(\\mathbf{x}_i, y_i) \\in \\mathcal{N}_k(\\mathbf{x}_*)} y_i\n",
    "$$\n",
    "\n",
    "Uma generaliza√ß√£o amplamente empregada utiliza pondera√ß√£o por dist√¢ncia, na qual vizinhos mais pr√≥ximos exercem maior influ√™ncia na predi√ß√£o **\\[[3, 5]()\\]**:\n",
    "\n",
    "$$\n",
    "\\hat{y}(\\mathbf{x}_*) = \\frac{\\sum_{i \\in \\mathcal{N}_k(\\mathbf{x}_*)}w_i(\\mathbf{x}_*)y_i}{\\sum_{i \\in \\mathcal{N}_k(\\mathbf{x}_*)}w_i(\\mathbf{x}_*)}\n",
    "$$\n",
    "\n",
    "Com pesos tipicamente definidos por:\n",
    "$$\n",
    "w_i(\\mathbf{x}_*) = \\frac{1}{d(\\mathbf{x}_*, \\mathbf{x}_i) + \\varepsilon}\n",
    "$$\n",
    "\n",
    "em que $\\varepsilon > 0$ evita singularidades num√©ricas **\\[[1]()\\]**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7360a715",
   "metadata": {},
   "source": [
    "### Natureza n√£o param√©trica e aus√™ncia de treinamento expl√≠cito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ce312",
   "metadata": {},
   "source": [
    "O $k$-NN √© classificado como um m√©todo *lazy learning*, pois n√£o constr√≥i um modelo expl√≠cito durante o treinamento **\\[[2]()\\]**. Todo o custo computacional √© transferido para a etapa de infer√™ncia, na qual √© necess√°rio calcular dist√¢ncias entre a amostra de teste e todas ‚Äî ou muitas ‚Äî das amostras de treinamento.\n",
    "\n",
    "Essa caracter√≠stica implica:\n",
    "- Custo de mem√≥ria proporcional a $\\mathcal{O}(Nd)$,\n",
    "- Custo de infer√™ncia proporcional a $\\mathcal{O}(Nd)$ por predi√ß√£o, na forma ing√™nua **\\[[4]()\\]**.\n",
    "\n",
    "Estruturas de dados como *KD-trees* e *Ball trees* podem reduzir esse custo em situa√ß√µes espec√≠ficas, embora sua efici√™ncia decaia em espa√ßos de alta dimensionalidade **\\[[5]()\\]**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbc2ee4",
   "metadata": {},
   "source": [
    "### Sensibilidade √† escala e pr√©-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853fafc7",
   "metadata": {},
   "source": [
    "Como o crit√©rio central do $k$-NN √© puramente geom√©trico, o algoritmo √© altamente sens√≠vel √† escala das *features*. Vari√°veis com maior amplitude num√©rica tendem a dominar o c√°lculo de dist√¢ncias, independentemente de sua relev√¢ncia sem√¢ntica ou f√≠sica **\\[[1]()\\]**.\n",
    "\n",
    "Por esse motivo, √© pr√°tica comum empregar normaliza√ß√£o ou padroniza√ß√£o dos dados. Contudo, em cen√°rios espec√≠ficos ‚Äî como quando as escalas originais carregam significado f√≠sico coerente ‚Äî o uso do espa√ßo original pode ser justific√°vel, desde que empiricamente validado **\\[[4]()\\]**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4ec7f",
   "metadata": {},
   "source": [
    "### Interpretabilidade e limita√ß√µes conceituais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4c8787",
   "metadata": {},
   "source": [
    "Diferentemente de modelos lineares ou baseados em √°rvores, o $k$-NN n√£o fornece par√¢metros interpret√°veis, coeficientes ou decomposi√ß√µes expl√≠citas de import√¢ncia das *features*. A predi√ß√£o emerge exclusivamente da distribui√ß√£o local dos dados, o que inviabiliza an√°lises diretas de interpretabilidade baseadas em coeficientes ou m√©todos como SHAP **\\[[6, 7]()\\]**.\n",
    "\n",
    "Assim, o $k$-NN deve ser compreendido como um estimador emp√≠rico local, cuja for√ßa reside na fidelidade interpolativa e cuja principal limita√ß√£o √© a aus√™ncia de uma representa√ß√£o expl√≠cita da rela√ß√£o funcional subjacente entre vari√°veis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7d15c",
   "metadata": {},
   "source": [
    "### Considera√ß√µes finais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946fc977",
   "metadata": {},
   "source": [
    "O algoritmo $k$-NN constitui um m√©todo conceitualmente simples, matematicamente direto e empiricamente poderoso para problemas de regress√£o e classifica√ß√£o baseados em similaridade. Ao abdicar de hip√≥teses param√©tricas globais, o $k$-NN √© capaz de capturar padr√µes locais complexos e n√£o lineares, desde que o espa√ßo de atributos seja adequadamente amostrado **\\[[1, 2]()\\]**.\n",
    "\n",
    "Entretanto, essa flexibilidade vem acompanhada de limita√ß√µes claras em termos de interpretabilidade, escalabilidade e extrapola√ß√£o. Dessa forma, o $k$-NN √© particularmente valioso como *baseline* emp√≠rico de alta fidelidade e como ferramenta complementar a modelos param√©tricos e interpret√°veis, contribuindo para uma avalia√ß√£o abrangente do espa√ßo de solu√ß√µes poss√≠veis em problemas de aprendizado supervisionado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df3967",
   "metadata": {},
   "source": [
    "# Metodologia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f2b90",
   "metadata": {},
   "source": [
    "### Importa√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d42b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import warnings\n",
    "\n",
    "from optuna import create_study\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import HyperbandPruner\n",
    "from optuna.trial import FixedTrial\n",
    "from optuna.exceptions import TrialPruned\n",
    "from optuna import load_study\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78536cf0",
   "metadata": {},
   "source": [
    "### Defini√ß√µes Globais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f23b9c",
   "metadata": {},
   "source": [
    "Defini√ß√µes de par√¢metros globais usados ao longo desse *Jupyter Notebook*, a fim de assegurar clareza metodol√≥gica e reprodutibilidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1c7aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 88\n",
    "PATH = '../../dataset_processing/xtb_dataset.csv'\n",
    "TRAIN_SIZE = 0.8\n",
    "STUDY_NAME = 'knn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126bf890",
   "metadata": {},
   "source": [
    "### Leitura dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb5842",
   "metadata": {},
   "source": [
    "Leitura do *dataset*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "811b0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH)\n",
    "\n",
    "X = df.drop(columns=['Delta'])\n",
    "y = df['Delta']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ca923",
   "metadata": {},
   "source": [
    "### Pr√©-processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7595aa7",
   "metadata": {},
   "source": [
    "Divis√£o do *dataset* em subconjuntos de dados de treino e teste, considerando as *features* e o *target*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f84f2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_SIZE, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d6f560",
   "metadata": {},
   "source": [
    "### Treino & Otimiza√ß√£o de Hiperpar√¢metros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbaa53",
   "metadata": {},
   "source": [
    "Inst√¢ncia do modelo com todos os hiperpar√¢metros e tratamentos a serem usados pelo `optuna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0765143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inst_knn(trial, n_features):\n",
    "\n",
    "\n",
    "    # Pr√©-processamento dispon√≠vel\n",
    "\n",
    "    pre_processing = trial.suggest_categorical(\n",
    "        \"pre_processing\", [None, \"VT\", \"PCA\"]\n",
    "    )\n",
    "\n",
    "    steps = []\n",
    "\n",
    "\n",
    "    # Normaliza√ß√£o (sempre obrigat√≥ria)\n",
    "\n",
    "    steps.append((\"scale\", StandardScaler()))\n",
    "\n",
    "\n",
    "    # Variance Threshold\n",
    "    if pre_processing == \"VT\":\n",
    "        threshold = trial.suggest_float(\n",
    "            \"variance_threshold\", 0.0, 1e-3\n",
    "        )\n",
    "        steps.append((\n",
    "            \"vt\", VarianceThreshold(threshold=threshold)\n",
    "        ))\n",
    "\n",
    "\n",
    "    # PCA\n",
    "    elif pre_processing == \"PCA\":\n",
    "        max_comp = min(n_features, 8)\n",
    "        n_comp = trial.suggest_int(\n",
    "            \"pca_components\", 2, max_comp\n",
    "        )\n",
    "        steps.append((\n",
    "            \"pca\", PCA(n_components=n_comp)\n",
    "        ))\n",
    "\n",
    "\n",
    "    # Hiperpar√¢metros do kNN\n",
    "    n_neighbors = trial.suggest_int(\n",
    "        \"n_neighbors\", 3, 50\n",
    "    )\n",
    "\n",
    "    weights = trial.suggest_categorical(\n",
    "        \"weights\", [\"uniform\", \"distance\"]\n",
    "    )\n",
    "\n",
    "    metric = trial.suggest_categorical(\n",
    "        \"metric\", [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "    )\n",
    "\n",
    "    p = 2\n",
    "    if metric == \"minkowski\":\n",
    "        p = trial.suggest_int(\"p\", 1, 2)\n",
    "\n",
    "\n",
    "    # Modelo kNN\n",
    "    steps.append((\n",
    "        \"knn\", KNeighborsRegressor(\n",
    "            n_neighbors=n_neighbors,\n",
    "            weights=weights,\n",
    "            metric=metric,\n",
    "            p=p,\n",
    "            n_jobs=1\n",
    "        )\n",
    "    ))\n",
    "\n",
    "    model = make_pipeline(*[s[1] for s in steps])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601eaead",
   "metadata": {},
   "source": [
    "Fun√ß√£o objetivo para valida√ß√£o cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7b65a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(trial, X, y, NUM_FOLDS=5):\n",
    "    n_features = X.shape[1]\n",
    "    cv = KFold(\n",
    "        n_splits=NUM_FOLDS,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "\n",
    "    rmse_folds = []\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        model = inst_knn(trial, n_features=n_features)\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            rmse = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        rmse_folds.append(rmse)\n",
    "\n",
    "        trial.report(np.mean(rmse_folds), step=i + 1)\n",
    "        if trial.should_prune():\n",
    "            raise TrialPruned()\n",
    "\n",
    "    return float(np.mean(rmse_folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac06a0d6",
   "metadata": {},
   "source": [
    "Fun√ß√µes para valida√ß√£o cruzada aninhada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15ec861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_fold(fold_idx, X, y, outer_splits, inner_splits, n_trials, pasta_estudos):\n",
    "    outer_cv = KFold(n_splits=outer_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    for fold, (idx_train, idx_test) in enumerate(outer_cv.split(X, y)):\n",
    "        if fold != fold_idx:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nFold externo {fold + 1}/{outer_splits}\")\n",
    "\n",
    "        X_train, X_test = X.iloc[idx_train], X.iloc[idx_test]\n",
    "        y_train, y_test = y.iloc[idx_train], y.iloc[idx_test]\n",
    "\n",
    "        db_path = os.path.join(\n",
    "            pasta_estudos,\n",
    "            f\"{STUDY_NAME}_fold_{fold + 1}.db\"\n",
    "        )\n",
    "\n",
    "        def inner_objective(trial):\n",
    "            return objective_function(\n",
    "                trial,\n",
    "                X_train,\n",
    "                y_train,\n",
    "                NUM_FOLDS=inner_splits\n",
    "            )\n",
    "\n",
    "        study = create_study(\n",
    "            study_name=f\"{STUDY_NAME}_fold_{fold + 1}\",\n",
    "            direction=\"minimize\",\n",
    "            sampler=TPESampler(seed=RANDOM_SEED),\n",
    "            pruner=HyperbandPruner(\n",
    "                min_resource=1,\n",
    "                max_resource=inner_splits,\n",
    "                reduction_factor=2\n",
    "            ),\n",
    "            storage=f\"sqlite:///{db_path}\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "\n",
    "        study.optimize(\n",
    "            inner_objective,\n",
    "            n_trials=n_trials,\n",
    "            n_jobs=1,\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "\n",
    "        print(\"Melhores hiperpar√¢metros encontrados:\")\n",
    "        print(study.best_params)\n",
    "\n",
    "        best_model = inst_knn(\n",
    "            FixedTrial(study.best_params),\n",
    "            n_features=X_train.shape[1]\n",
    "        )\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "            best_model.fit(X_train, y_train)\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            rmse_test = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        print(f\"RMSE de teste externo (fold {fold + 1}): {rmse_test:.4f}\")\n",
    "        return rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e774c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(X, y, outer_splits=5, inner_splits=3, n_trials=200, studies_folder=f\"optuna_{STUDY_NAME}_studies\"):\n",
    "    os.makedirs(studies_folder, exist_ok=True)\n",
    "    outer_scores = []\n",
    "\n",
    "    for fold in range(outer_splits):\n",
    "        rmse_fold = nested_cv_fold(\n",
    "            fold_idx=fold,\n",
    "            X=X,\n",
    "            y=y,\n",
    "            outer_splits=outer_splits,\n",
    "            inner_splits=inner_splits,\n",
    "            n_trials=n_trials,\n",
    "            studies_folder=studies_folder\n",
    "        )\n",
    "        outer_scores.append(rmse_fold)\n",
    "\n",
    "    outer_scores = np.array(outer_scores)\n",
    "\n",
    "    print(\"\\n========================\")\n",
    "    print(\"Resultados do Nested CV:\")\n",
    "    print(f\"RMSE m√©dio: {outer_scores.mean():.4f}\")\n",
    "    print(f\"Desvio padr√£o: {outer_scores.std():.4f}\")\n",
    "    print(\"========================\")\n",
    "\n",
    "    return outer_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6eec6",
   "metadata": {},
   "source": [
    "Execu√ß√£o dos estudos de otimiza√ß√£o de hiperpar√¢metros do `optuna`:\n",
    "\n",
    "> **üìå Observa√ß√£o:** O seguinte c√≥digo est√° comentado como c√©lula Markdown por apresentar elevado custo computacional. Desse modo, √© recomendada execu√ß√£o do *script* `kNN.py` utilizando computa√ß√£o de alto desempenho (HPC) a fim de garantir efici√™ncia e estabilidade computacional na execu√ß√£o dos estudos de otimiza√ß√£o. Ap√≥s isso, basta o diret√≥rio `svr_knn_studies` para o mesmo diret√≥rio desse *Jupyter Notebook* e executar as c√©lulas seguintes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d8357",
   "metadata": {},
   "source": [
    "---\n",
    "```python\n",
    "results = nested_cv(X_train, y_train, outer_splits=5, inner_splits=3, n_trials=100)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1fa1b5",
   "metadata": {},
   "source": [
    "Acesso aos estudos de otimiza√ß√£o, para extra√ß√£o dos melhores valores dos hiperpar√¢metros e o desempenho obtido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39867107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos .db encontrados:\n",
      "- knn_fold_1.db\n",
      "- knn_fold_2.db\n",
      "- knn_fold_3.db\n",
      "- knn_fold_4.db\n",
      "- knn_fold_5.db\n"
     ]
    }
   ],
   "source": [
    "studies_folder = f\"optuna_{STUDY_NAME}_studies\"\n",
    "db_files = [f for f in os.listdir(studies_folder) if f.endswith(\".db\")]\n",
    "\n",
    "print(\"Arquivos .db encontrados:\")\n",
    "for f in db_files:\n",
    "    print(\"-\", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5949118",
   "metadata": {},
   "source": [
    "Melhores hiperpar√¢metros obtidos durante a otimiza√ß√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9945c846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= knn_fold_1 =======\n",
      "  Melhor valor: 0.0588802\n",
      "  Par√¢metros: {'pre_processing': None, 'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "\n",
      "======= knn_fold_2 =======\n",
      "  Melhor valor: 0.0580648\n",
      "  Par√¢metros: {'pre_processing': None, 'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "\n",
      "======= knn_fold_3 =======\n",
      "  Melhor valor: 0.0583172\n",
      "  Par√¢metros: {'pre_processing': None, 'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "\n",
      "======= knn_fold_4 =======\n",
      "  Melhor valor: 0.0605619\n",
      "  Par√¢metros: {'pre_processing': None, 'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "\n",
      "======= knn_fold_5 =======\n",
      "  Melhor valor: 0.0581896\n",
      "  Par√¢metros: {'pre_processing': None, 'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "\n",
      "RMSE m√©dio: 0.0588027\n",
      "Desvio padr√£o: 0.0009227\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for file in db_files:\n",
    "    path = os.path.join(studies_folder, file)\n",
    "    study_name = file.replace('.db', '')\n",
    "    \n",
    "    try:\n",
    "        study = load_study(study_name=study_name, storage=f\"sqlite:///{path}\")\n",
    "        best_trial = study.best_trial\n",
    "        \n",
    "        print(f'======= {study_name} =======')\n",
    "        print(f\"  Melhor valor: {best_trial.value:.7f}\")\n",
    "        print(f\"  Par√¢metros: {best_trial.params}\\n\")\n",
    "        \n",
    "        results.append({\n",
    "            \"fold\": study_name,\n",
    "            \"best_value\": best_trial.value,\n",
    "            \"params\": best_trial.params\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"N√£o foi poss√≠vel carregar {study_name}: {e}\")\n",
    "\n",
    "# Exibe melhores resultados\n",
    "if results:\n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(f\"RMSE m√©dio: {np.mean(df_results['best_value']):.7f}\")\n",
    "    print(f\"Desvio padr√£o: {np.std(df_results['best_value']):.7f}\")\n",
    "else:\n",
    "    print(\"Nenhum estudo p√¥de ser carregado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af6e2f",
   "metadata": {},
   "source": [
    "Desempenho do melhor modelo obtido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93e4978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor fold: knn_fold_2\n",
      "Melhor desempenho (RMSE): 0.05806481966872507\n",
      "Melhores par√¢metros: {'pre_processing': None, 'n_neighbors': 4, 'weights': 'distance', 'metric': 'manhattan'}\n"
     ]
    }
   ],
   "source": [
    "# df j√° cont√©m os melhores trials de cada fold\n",
    "best_fold = df_results.loc[df_results['best_value'].idxmin()]  # menor RMSE\n",
    "print(\"Melhor fold:\", best_fold['fold'])\n",
    "print(\"Melhor desempenho (RMSE):\", best_fold['best_value'])\n",
    "print(\"Melhores par√¢metros:\", best_fold['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a6a0e",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a79785",
   "metadata": {},
   "source": [
    "Treino e teste finais para avalia√ß√£o do melhor modelo obtido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3107ae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE do melhor modelo: 0.03311216742845702\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors=4, weights='distance', metric='manhattan')\n",
    "\n",
    "best_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"estimator\", knn_model)\n",
    "])\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f'RMSE do melhor modelo: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5ff5d",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f0b7f",
   "metadata": {},
   "source": [
    "O melhor modelo induzido a partir do algoritmo $k$-NN durante a otimiza√ß√£o de hiperpar√¢metros do `optuna` obteve $\\mathrm{RMSE}$ de $\\approx 0.06$, dotado dos seguintes hiperpar√¢metros tabulados e com o conjunto de dados original, sem qualquer tipo de pr√©-processamento das *features*.\n",
    "\n",
    "| Hiperpar√¢metros | Valor       |\n",
    "|-----------------|-------------|\n",
    "| `n_neighbors`   | $4$         |\n",
    "| `weights`       | `distance`  |\n",
    "| `metric`        | `manhattan` |\n",
    "\n",
    "Por fim, ao desenvolver o teste final, o modelo induzido com os hiperpar√¢metros supracitados obteve $\\mathrm{RMSE}$ de $\\approx 0.03$, objetivamente menor, mas com mesma ordem de grandeza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f0c39",
   "metadata": {},
   "source": [
    "# Conclus√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6cb1d",
   "metadata": {},
   "source": [
    "A an√°lise do desempenho do modelo $k$-NN, fundamentada exclusivamente em m√©tricas quantitativas e no comportamento algor√≠tmico intr√≠nseco do m√©todo, conduz a uma conclus√£o complementar ‚Äî e conceitualmente distinta ‚Äî daquela obtida para os modelos param√©tricos e interpret√°veis empregados ao longo do projeto.\n",
    "\n",
    "O melhor modelo induzido via otimiza√ß√£o de hiperpar√¢metros com o `optuna` apresentou desempenho preditivo elevado, com $\\mathrm{RMSE} \\approx 0.06$ durante a etapa de sele√ß√£o e $\\mathrm{RMSE} \\approx 0.03$ no teste final. Embora o valor obtido no conjunto final seja objetivamente menor, ambos pertencem √† mesma ordem de grandeza, o que indica aus√™ncia de instabilidade severa entre fases de valida√ß√£o e teste, bem como uma generaliza√ß√£o adequada dentro do regime de vizinhan√ßa local caracter√≠stico do $k$-NN.\n",
    "\n",
    "A configura√ß√£o √≥tima ‚Äî $k = 4$, pondera√ß√£o por dist√¢ncia e m√©trica Manhattan ‚Äî revela aspectos estruturais importantes do espa√ßo de atributos. O baixo n√∫mero de vizinhos indica que o modelo se beneficia de rela√ß√µes altamente locais, explorando regi√µes densas e coerentes do espa√ßo de *features*, em vez de tend√™ncias globais suaves. A escolha de `weights='distance'` refor√ßa essa interpreta√ß√£o, ao atribuir maior influ√™ncia a observa√ß√µes mais pr√≥ximas, reduzindo o impacto de pontos potencialmente ruidosos ou marginalmente similares. J√° a m√©trica Manhattan sugere que diferen√ßas absolutas coordenada a coordenada s√£o mais informativas do que dist√¢ncias euclidianas globais, o que √© consistente com um espa√ßo de atributos heterog√™neo, possivelmente composto por vari√°veis de diferentes naturezas f√≠sicas e escalas.\n",
    "\n",
    "√â particularmente relevante notar que o melhor desempenho foi obtido sem qualquer tipo de pr√©-processamento das *features*. Esse resultado indica que o pr√≥prio arranjo geom√©trico dos dados no espa√ßo original j√° √© suficientemente informativo para permitir uma boa discrimina√ß√£o local entre inst√¢ncias. Ao mesmo tempo, essa caracter√≠stica evidencia a sensibilidade do $k$-NN √† escala e √† distribui√ß√£o das vari√°veis, refor√ßando que o bom desempenho observado depende fortemente da estrutura espec√≠fica do dataset, e n√£o de uma robustez algor√≠tmica generaliz√°vel no sentido estrito.\n",
    "\n",
    "Diferentemente dos modelos lineares regularizados e do SVR, o $k$-NN n√£o admite uma decomposi√ß√£o expl√≠cita de contribui√ß√µes individuais das *features*, inviabilizando an√°lises do tipo SHAP. Consequentemente, sua elevada performance n√£o decorre da identifica√ß√£o de uma subestrutura f√≠sica interpret√°vel de baixa dimensionalidade, mas sim da capacidade de interpola√ß√£o local em regi√µes bem amostradas do espa√ßo de dados. Nesse sentido, o modelo atua mais como um estimador n√£o param√©trico de alta fidelidade local do que como um mecanismo de infer√™ncia estrutural.\n",
    "\n",
    "Em s√≠ntese, o modelo $k$-NN demonstra excelente capacidade preditiva para o dataset em quest√£o, sendo particularmente eficaz na captura de padr√µes locais finos sem impor hip√≥teses funcionais expl√≠citas. Todavia, esse desempenho vem acompanhado de limita√ß√µes claras em termos de interpretabilidade f√≠sica, extrapola√ß√£o e robustez fora do dom√≠nio amostrado. Assim, o $k$-NN se consolida como um modelo de refer√™ncia emp√≠rica de alto desempenho, √∫til para estabelecer limites superiores pr√°ticos de erro, mas conceitualmente complementar ‚Äî e n√£o substituto ‚Äî aos modelos param√©tricos e interpret√°veis que fundamentam a compreens√£o f√≠sica do problema ao longo do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abcab0a",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d1922",
   "metadata": {},
   "source": [
    "[1] HASTIE, Trevor; TIBSHIRANI, Robert; FRIEDMAN, Jerome. *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*. 2. ed. New York: Springer, 2009.\n",
    "\n",
    "[2] BISHOP, Christopher M. *Pattern Recognition and Machine Learning*. New York: Springer, 2006.\n",
    "\n",
    "[3] DUDOIT, Sandrine; FRIDLYAND, Jane. Classification in microarray experiments. *Statistical Analysis of Gene Expression Microarray Data*. Boca Raton: Chapman & Hall/CRC, 2003.\n",
    "\n",
    "[4] JAMES, Gareth et al. *An Introduction to Statistical Learning*. 2. ed. New York: Springer, 2021.\n",
    "\n",
    "[5] PEDREGOSA, Fabian et al. Scikit-learn: Machine Learning in Python. *Journal of Machine Learning Research*, v. 12, p. 2825‚Äì2830, 2011.\n",
    "\n",
    "[6] COVER, Thomas; HART, Peter. Nearest neighbor pattern classification. *IEEE Transactions on Information Theory*, v. 13, n. 1, p. 21‚Äì27, 1967.\n",
    "\n",
    "[7] MOLNAR, Christoph. *Interpretable Machine Learning*. 2. ed. 2022. Dispon√≠vel em: [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/). Acesso em: 26 Dez. 2025."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
